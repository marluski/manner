<!-- Creator     : groff version 1.23.0 -->
<!-- CreationDate: Mon Apr  7 17:32:29 2025 -->
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
<meta name="generator" content="groff -Thtml, see www.gnu.org">
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII">
<meta name="Content-Style" content="text/css">
<style type="text/css">
       p       { margin-top: 0; margin-bottom: 0; vertical-align: top }
       pre     { margin-top: 0; margin-bottom: 0; vertical-align: top }
       table   { margin-top: 0; margin-bottom: 0; vertical-align: top }
       h1      { text-align: center }
</style>
<title>y4mdenoise</title>

</head>
<body>

<h1 align="center">y4mdenoise</h1>

<a href="#NAME">NAME</a><br>
<a href="#SYNOPSIS">SYNOPSIS</a><br>
<a href="#DESCRIPTION">DESCRIPTION</a><br>
<a href="#HOW IT WORKS">HOW IT WORKS</a><br>
<a href="#OPTIONS">OPTIONS</a><br>
<a href="#TYPICAL USAGE AND TIPS">TYPICAL USAGE AND TIPS</a><br>
<a href="#AUTHOR">AUTHOR</a><br>
<a href="#FURTHER INFO">FURTHER INFO</a><br>
<a href="#SEE ALSO">SEE ALSO</a><br>

<hr>


<h2>NAME
<a name="NAME"></a>
</h2>


<p style="margin-left:9%; margin-top: 1em">y4mdenoise -
Motion-compensating YUV4MPEG-frame denoiser</p>

<h2>SYNOPSIS
<a name="SYNOPSIS"></a>
</h2>



<p style="margin-left:9%; margin-top: 1em"><b>y4mdenoise</b>
[<b>-v</b> <i>verbosity</i>] [<b>-p</b> <i>parallelism</i>]
[<b>-r</b> <i>motion-search_radius</i>] [<b>-R</b>
<i>color_motion-search_radius</i>] [<b>-t</b>
<i>error_tolerance</i>] [<b>-T</b>
<i>color_error_tolerance</i>] [<b>-z</b>
<i>zero_motion_error_tolerance</i>] [<b>-Z</b>
<i>color_zero_motion_error_tolerance</i>] [<b>-m</b>
<i>match-count_throttle</i>] [<b>-M</b>
<i>match-size_throttle</i>] [<b>-f</b>
<i>reference_frames</i>] [<b>-B</b>] [<b>-I</b>
<i>interlacing_type</i>] &lt; /dev/stdin &gt;
/dev/stdout</p>

<h2>DESCRIPTION
<a name="DESCRIPTION"></a>
</h2>



<p style="margin-left:9%; margin-top: 1em"><b>y4mdenoise</b>
can be used to remove noise from images in a YUV4MPEG2
stream. This is useful for cleaning old sources to increase
video quality, and to reduce the bitrate needed to encode
your video (e.g. for VCD and SVCD creation).</p>

<h2>HOW IT WORKS
<a name="HOW IT WORKS"></a>
</h2>


<p style="margin-left:9%; margin-top: 1em">It maintains a
list of the last several frames, called reference frames.
Each reference frame is composed of reference pixels. Every
time a pixel in one frame is proven to be a moved instance
of a pixel in another frame, the reference-pixel
incorporates its value, and produces an average value for
all instances of the pixel. The oldest reference frame,
therefore, gets a pretty good idea of the real value of
every pixel, but of course output is delayed by the number
of reference frames.</p>

<p style="margin-left:9%; margin-top: 1em">The search is
not actually done one pixel at a time; it&rsquo;s done in
terms of pixel groups. An entire pixel-group has to match
for any match to be found, but all possible pixel-groups are
tested (i.e. all possible overlapping combinations are
checked). Using pixel-groups helps to establish a minimum
standard for what may be considered a match, in order to
avoid finding lots of really small (and really useless)
matches. Presently, intensity pixel-groups are 4x2 (i.e. 4
across and 2 down), and color pixel-groups are 2x2.</p>

<p style="margin-left:9%; margin-top: 1em">It compares
every pixel-group in the current frame with all pixel-groups
in the previous frame, within a given search-radius, and
sorts them based on how close the match was, keeping the top
contenders. It then flood-fills each found pixel-group in
turn, to determine the full size of the match. The first
match found to be big enough is applied to the image. The
number of contenders to consider, and the minimum size of a
match, can be specified on the command line.</p>

<p style="margin-left:9%; margin-top: 1em">At the end of
the frame, any new-frame pixels not resolved yet are
considered to be new information, and a new reference-pixel
is generated for each one.</p>

<p style="margin-left:9%; margin-top: 1em">A
&quot;zero-motion pass&quot; happens each frame, before
motion-detection, in an attempt to resolve most of the frame
cheaply. Its error-tolerance can be set separately.</p>

<h2>OPTIONS
<a name="OPTIONS"></a>
</h2>



<p style="margin-left:9%; margin-top: 1em"><b>y4mdenoise</b>
accepts the following options: <b><br>
-v</b> <i>[0..2] verbosity</i></p>

<p style="margin-left:14%;">0 = none, 1 = normal (per-frame
pixel-detection totals), 2=debug.</p>

<p style="margin-left:9%;"><b>-p</b> <i>num</i></p>

<p style="margin-left:14%;">Controls the level of
parallelism. Since intensity and color are denoised
separately by design, it&rsquo;s very easy to do each in
parallel on a multiple-processor machine. The default value
is 1; that reads and writes video frames in parallel with
denoising. A value of 2 causes intensity and color to be
denoised in parallel. A value of 3 does both types of
concurrency. A value of 0 turns off all concurrency.</p>

<p style="margin-left:9%;"><b>-r</b> <i>[4..] search
radius</i></p>

<p style="margin-left:14%;">The search radius, i.e. the
maximum distance that a pixel can move and still be found by
motion-detection. The default is 16. There are no particular
restrictions on the search radius, e.g. it doesn&rsquo;t
have to be an even multiple of 4.</p>

<p style="margin-left:9%;"><b>-R</b> <i>[4..] color search
radius</i></p>

<p style="margin-left:14%;">The search radius to use for
color. Default is whatever the main search-radius was set
to. Note that this value ends up getting scaled by the
relative size of intensity &amp; color planes in your
YUV4MPEG2 stream.</p>

<p style="margin-left:9%;"><b>-t</b> <i>[0..255] Error
tolerance</i></p>

<p style="margin-left:14%;">The largest difference between
two pixels that&rsquo;s accepted for the two pixels to be
considered equal. The default is 3, which is good for
medium-noise material like analog cable TV. (This value will
have to be changed to whatever is appropriate for your
YUV4MPEG2 stream in order to avoid undesirable results. See
the instructions below.)</p>

<p style="margin-left:9%;"><b>-T</b> <i>[0..255] Error
tolerance for color</i></p>

<p style="margin-left:14%;">The default is whatever the
main error-tolerance was set to.</p>

<p style="margin-left:9%;"><b>-z</b> <i>[0..255] Error
tolerance for zero-motion pass</i></p>

<p style="margin-left:14%;">The error-tolerance used on
pixels that haven&rsquo;t moved. Usually equal to the main
error-tolerance or one less than that. Default is 2.</p>

<p style="margin-left:9%;"><b>-Z</b> <i>[0..255] Error
tolerance for color&rsquo;s zero-motion pass</i></p>

<p style="margin-left:14%;">The default is whatever the
main zero-motion error-tolerance was set to.</p>

<p style="margin-left:9%;"><b>-m</b> <i>[num] Match-count
throttle</i></p>

<p style="margin-left:14%;">The maximum number of
pixel-group matches (within the search radius) to consider.
If more are found, only the closest matches are kept.
Default is 15.</p>

<p style="margin-left:9%;"><b>-M</b> <i>[num] Match-size
throttle</i></p>

<p style="margin-left:14%;">The minimum size of the
flood-filled region generated from a match. Matches smaller
than this are thrown away. Specified in terms of
pixel-groups. Default is 3.</p>

<p style="margin-left:9%;"><b>-f</b> <i>num</i></p>

<p style="margin-left:14%;">The number of reference frames
to keep. Pixel values are averaged over this many frames
before they&rsquo;re written to standard output; this also
implies that output is delayed by this many frames. Default
is 10.</p>

<table width="100%" border="0" rules="none" frame="void"
       cellspacing="0" cellpadding="0">
<tr valign="top" align="left">
<td width="9%"></td>
<td width="3%">


<p><b>-B</b></p></td>
<td width="2%"></td>
<td width="86%">


<p>Black-and-white mode. Denoise only the intensity plane,
and set the color plane to all white.</p></td></tr>
</table>

<p style="margin-left:9%;"><b>-I</b> <i>num</i></p>

<p style="margin-left:14%;">Set interlacing type. Default
is taken from the YUV4MPEG2 stream. 0 means not interlaced,
1 means top-field interlaced, 2 means bottom-field
interlaced. This is useful when the signal is more naturally
of some other interlacing type than its current
representation (e.g. if the original was shot on film and
then later it was transferred to interlaced video, it will
denoise better if treated as film, i.e. non-interlaced).</p>

<h2>TYPICAL USAGE AND TIPS
<a name="TYPICAL USAGE AND TIPS"></a>
</h2>


<p style="margin-left:9%; margin-top: 1em">Keep in mind
that all of this advice was gained through experience. (Just
because one writes a tool doesn&rsquo;t mean one understands
how it should be used, for the same reason that car
designers aren&rsquo;t necessarily professional
drivers.)</p>

<p style="margin-left:9%; margin-top: 1em">The
error-threshold must be determined for every individual
YUV4MPEG2 stream. If the threshold is set too low,
it&rsquo;ll leave noise in the video, and the denoiser will
run a lot slower than it has to. If it&rsquo;s set too high,
the denoiser will start to remove detail: the video will get
blurrier, you may see topographical-like bands in the
relatively flat areas of the video, and small parts of the
video that should be moving will be stuck in place. It may
also run a little slower. Additionally, just because the
video came to you from a clean source (digital cable TV,
LaserDisc, etc.) doesn&rsquo;t mean the video itself is
clean; <b>y4mdenoise</b> is capable of picking up on noise
in the original recording as well as sampling error from the
video-capture device. You will have to generate small clips
of representative parts of your video, denoise them with
various error thresholds, and see what looks the best. As
you gain experience with the tool, you may know what error
threshold generally works with various types of sources, but
you&rsquo;ll still want to double-check your
assumptions.</p>

<p style="margin-left:9%; margin-top: 1em">Flat, shiny
surfaces, like gloss-painted walls, or the polished wood
floor of an indoor gymnasium, seem to require a lower error
threshold than other types of video.</p>

<p style="margin-left:9%; margin-top: 1em">Here is the
author&rsquo;s experience:</p>

<p style="margin-left:9%; margin-top: 1em">-t 1 : Digital
cable TV, most LaserDiscs, DV camcorder video <br>
-t 2 : VHS camcorder video, commercially-produced videotapes
<br>
-t 3 : Analog cable TV, VHS videotape (at the 2-hour speed)
<br>
-t 4 : VHS videotape (at the 6-hour speed)</p>

<p style="margin-left:9%; margin-top: 1em">Interlaced video
that was made from non-interlaced video (e.g. a videotape or
LaserDisc of a film) must be denoised as non-interlaced.
Otherwise the result tends to be grainy.</p>


<p style="margin-left:9%; margin-top: 1em"><b>y4mdenoise</b>
only removes temporal noise, i.e. noise that occurs over
time. And it tends to do such a good job of this, that the
spatial noise (i.e. noise that occurs in nearby areas of the
same frame) tends to become very distinct. Therefore, always
pipe the output of <b>y4mdenoise</b> through a spatial
filter such as <b>y4mspatialfilter</b> or
<b>yuvmedianfilter</b>.</p>

<p style="margin-left:9%; margin-top: 1em">When producing
very low bitrate video (e.g. VCD-compatible video less than
900 kbps), denoise at the output frame size, e.g.
don&rsquo;t denoise at DVD frame size then downscale to VCD
size. That will denoise as well as condition the video for
the motion-detection part of <b>mpeg2enc</b>. Not doing this
will produce video where the less complex scenes will look
really good, but high-motion scenes will blur
significantly.</p>

<p style="margin-left:9%; margin-top: 1em">JPEG compression
of your video frames, even 100% compression, seems to be
inaccurate enough to affect MPEG encoding. Therefore, if
you&rsquo;re using motion-JPEG files as your intermediary
video format, you may want to use the denoiser in your
MPEG-encoding pipeline, i.e. after <b>lav2yuv</b> and before
<b>mpeg2enc</b>. If you&rsquo;re generating multiple
resolutions of the same video, e.g. DVD and VCD, experience
shows that it&rsquo;s acceptable to run <b>y4mdenoise</b>
before <b>yuv2lav</b>, but you should still use the
spatial-filter (e.g. <b>y4mspatialfilter</b>,
<b>yuvmedianfilter</b>) in the MPEG-encoding pipeline, to
try to smooth away JPEG encoding artifacts.</p>

<h2>AUTHOR
<a name="AUTHOR"></a>
</h2>


<p style="margin-left:9%; margin-top: 1em">The bulk of the
<b>y4mdenoise</b> code, and this manual page, was written by
Steven Boswell &lt;ulatec@users.sourceforge.net&gt;.</p>

<h2>FURTHER INFO
<a name="FURTHER INFO"></a>
</h2>


<p style="margin-left:9%; margin-top: 1em">If you have
questions, remarks, problems or you just want to contact the
developers, the main mailing list for the MJPEG-tools
is:</p>


<p style="margin-left:9%; margin-top: 1em"><i>mjpeg-users@lists.sourceforge.net</i></p>

<p style="margin-left:9%; margin-top: 1em">For more info,
see our website at</p>


<p style="margin-left:9%; margin-top: 1em"><i>http://mjpeg.sourceforge.net/</i></p>

<h2>SEE ALSO
<a name="SEE ALSO"></a>
</h2>



<p style="margin-left:9%; margin-top: 1em"><i><b>mjpegtools</b></i>(1),
<b>mpeg2enc</b>(1), <b>yuvdenoise</b>(1),
<b>yuvmedianfilter</b>(1)</p>
<hr>
</body>
</html>
